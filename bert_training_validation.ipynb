{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_training_validation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hrBUScizmz2o",
        "C-ox0s5lAJ5p",
        "NSTj69zcASO_",
        "_c3wBkpT3VVE",
        "kUx4bMxVAqpy",
        "Haw55dBspsk6",
        "E9wrZGE9pwuR",
        "MMWvmFsKrug2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d354d7097264df8a423cfac210ef680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33876eef007e4159b2110f185e296501",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c147ada793448b08770db5a76261cc9",
              "IPY_MODEL_c6eb0465d498473fb589809de536f6c5"
            ]
          }
        },
        "33876eef007e4159b2110f185e296501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c147ada793448b08770db5a76261cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2a6b4a131dd4bd59489f29644580344",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f647fd5ea53f4386893ed8b750f463bc"
          }
        },
        "c6eb0465d498473fb589809de536f6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a93efd826a94ac49630c9fec8bb8d56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 681kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc7309c26203422db74df825a3750c74"
          }
        },
        "c2a6b4a131dd4bd59489f29644580344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f647fd5ea53f4386893ed8b750f463bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a93efd826a94ac49630c9fec8bb8d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc7309c26203422db74df825a3750c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a18080db34a046f181b57b354f19708b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d9ba9cd727944b1b094a643a8109dc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bf2a90bfdf94bdcb045762ee62b31c3",
              "IPY_MODEL_247f8bc86e9e473f8dc465a8d4a73f73"
            ]
          }
        },
        "2d9ba9cd727944b1b094a643a8109dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bf2a90bfdf94bdcb045762ee62b31c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86ed49453f124b54ac4734ece4313c81",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ac6e5db12e444649413f8c6a436b459"
          }
        },
        "247f8bc86e9e473f8dc465a8d4a73f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00641e99263f49e7be07bfa3fde1e51b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac9746a24d8847ebb492091e11f9334b"
          }
        },
        "86ed49453f124b54ac4734ece4313c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ac6e5db12e444649413f8c6a436b459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00641e99263f49e7be07bfa3fde1e51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac9746a24d8847ebb492091e11f9334b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5c469c4b5e24b178555fcd2d71217d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bd7366069d24a09a96616f175728332",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_267069f4c28248ed9e6a0b96ef505540",
              "IPY_MODEL_84a9fb93a46345078a0640dd825e313f"
            ]
          }
        },
        "9bd7366069d24a09a96616f175728332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "267069f4c28248ed9e6a0b96ef505540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc4accf27dce478caf2ca15e70a8046e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcaa4dfcf2204243be5f4ee414b81df5"
          }
        },
        "84a9fb93a46345078a0640dd825e313f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47ec3ad78fd44d24901f4f037aa8ddc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:17&lt;00:00, 27.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d45bca6976964c139dc72e0d6dc28607"
          }
        },
        "bc4accf27dce478caf2ca15e70a8046e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcaa4dfcf2204243be5f4ee414b81df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47ec3ad78fd44d24901f4f037aa8ddc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d45bca6976964c139dc72e0d6dc28607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "419275a22e9b4d37bac7e5b8358324a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a4113ccc4fc4c1f88a501c9cd0df52d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7842520d26a247dc82288b4bdf324276",
              "IPY_MODEL_0b4e2abbe9fc4f108410047f58ca4c7d"
            ]
          }
        },
        "9a4113ccc4fc4c1f88a501c9cd0df52d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7842520d26a247dc82288b4bdf324276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c27d2f116414c6b8a98fa407a5f61fb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72647df2b8bc47ee9959041bfe2c5920"
          }
        },
        "0b4e2abbe9fc4f108410047f58ca4c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eca8b32cf837469d846fad1eef60c129",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:16&lt;00:00, 29.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_748d235ca9f643f890cc0f8e5f055e22"
          }
        },
        "1c27d2f116414c6b8a98fa407a5f61fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72647df2b8bc47ee9959041bfe2c5920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eca8b32cf837469d846fad1eef60c129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "748d235ca9f643f890cc0f8e5f055e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgbAo8kx_8QV",
        "colab_type": "text"
      },
      "source": [
        "# Essentially a copy of [this Colab NB](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX?usp=sharing) from Chris McCormick and Nick Ryan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6CyImjelhBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "99ff8f11-f133-4b61-9004-ec02c17f1323"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WIdwW53muEK",
        "colab_type": "text"
      },
      "source": [
        "# <span style=\"color:#FF8800\"> (Most) Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyvuUOpmOII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbb2f6a-3efe-4c06-aa4f-2784911cf93f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3664069fd5e8a703c41432734af7b1c84ffe992b2cc731eba13acedd739a472f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGcqDxobl_OI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6282b2a3-c4f9-4b0e-ab94-2ab5fae5807e"
      },
      "source": [
        "#standard library imports\n",
        "import datetime\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "#3rd party imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "#local app & library specific imports\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score, precision_recall_fscore_support #classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, random_split, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrBUScizmz2o",
        "colab_type": "text"
      },
      "source": [
        "# <span style=\"color:#FF8800\"> Setup & global vars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5vNTOtlsU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68a03bbb-ff98-4952-be7b-caa5abc03f2c"
      },
      "source": [
        "%cd drive/'My Drive'/propaganda_bert/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/propaganda_bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9GwaCdJl333",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "861c5db9-636a-4149-b6c6-e6ed4fac7f07"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0hNRJdl7iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e919b5a2-f343-4624-9cb1-254d13ee0316"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "train_df = pd.read_csv(\n",
        "    \"datasets/train_data.tsv\",\n",
        "    sep = \"\\t\",\n",
        "    header = 0,\n",
        "    index_col = 0\n",
        ")\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 15,928\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdUfpFvmWXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "cf77ede7-0c86-486e-a79a-593899af2cdc"
      },
      "source": [
        "train_df.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_binary</th>\n",
              "      <th>rand_letter</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1935</th>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>\\nA point that Dreher’s informants have brough...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3759</th>\n",
              "      <td>Exaggeration,Minimisation</td>\n",
              "      <td>Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>the most wayward Pope in Church history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>who hold views counter to Christian belief, bu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          label  ...                                               text\n",
              "1935              No_Propaganda  ...  \\nA point that Dreher’s informants have brough...\n",
              "3759  Exaggeration,Minimisation  ...            the most wayward Pope in Church history\n",
              "618               No_Propaganda  ...  who hold views counter to Christian belief, bu...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jajcAhXdo0xF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e906968-9cb5-4608-9d9b-4d4b86e7f8ac"
      },
      "source": [
        "#Global vars - vars in ALL_CAPS can be adjusted to enable experiments\n",
        "\n",
        "#Dataset vars\n",
        "THESE_LABELS = \"label\"\n",
        "NUM_LABELS = train_df[THESE_LABELS].nunique()\n",
        "print(f\"NUM_LABELS: {NUM_LABELS}\")\n",
        "\n",
        "#BERT/Training vars\n",
        "MODEL = \"roberta-base\"\n",
        "EPOCHS = 3 #Good starting range is 2 to 4\n",
        "LEARNING_RATE = 5e-5 #Good starting range is 2e-5 to 5e-5\n",
        "BATCH_SIZE = 32 #For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_LABELS: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc-SwcvepYhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "a434c573-402d-4ce9-d223-3feb3406c74d"
      },
      "source": [
        "sentences = train_df.text.values\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(train_df[THESE_LABELS]) #encode labels as ints\n",
        "\n",
        "counter = 0\n",
        "for entry in le.classes_:\n",
        "  print(f\"{counter}: {entry}\")\n",
        "  counter += 1\n",
        "\n",
        "train_df[THESE_LABELS+\"_encoded\"] = labels #add col to train_df with ints for labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Appeal_to_Authority\n",
            "1: Appeal_to_fear-prejudice\n",
            "2: Bandwagon,Reductio_ad_hitlerum\n",
            "3: Black-and-White_Fallacy\n",
            "4: Causal_Oversimplification\n",
            "5: Doubt\n",
            "6: Exaggeration,Minimisation\n",
            "7: Flag-Waving\n",
            "8: Loaded_Language\n",
            "9: Name_Calling,Labeling\n",
            "10: No_Propaganda\n",
            "11: Repetition\n",
            "12: Slogans\n",
            "13: Thought-terminating_Cliches\n",
            "14: Whataboutism,Straw_Men,Red_Herring\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgsx46ayVUcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "c8b6384b-ea38-4ea4-9a47-ae7bda3fc91f"
      },
      "source": [
        "train_df.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_binary</th>\n",
              "      <th>rand_letter</th>\n",
              "      <th>text</th>\n",
              "      <th>label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13040</th>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>our free speech victory</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3836</th>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>No_Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>the church in fear of deportation.\\n[Indonesia...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15803</th>\n",
              "      <td>Repetition</td>\n",
              "      <td>Propaganda</td>\n",
              "      <td>s</td>\n",
              "      <td>Freemasonry</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 label  ... label_encoded\n",
              "13040  Loaded_Language  ...             8\n",
              "3836     No_Propaganda  ...            10\n",
              "15803       Repetition  ...            11\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ox0s5lAJ5p",
        "colab_type": "text"
      },
      "source": [
        "# Get tokenizer & tokenize training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNwugkqkpcRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "5d354d7097264df8a423cfac210ef680",
            "33876eef007e4159b2110f185e296501",
            "2c147ada793448b08770db5a76261cc9",
            "c6eb0465d498473fb589809de536f6c5",
            "c2a6b4a131dd4bd59489f29644580344",
            "f647fd5ea53f4386893ed8b750f463bc",
            "6a93efd826a94ac49630c9fec8bb8d56",
            "dc7309c26203422db74df825a3750c74",
            "a18080db34a046f181b57b354f19708b",
            "2d9ba9cd727944b1b094a643a8109dc2",
            "0bf2a90bfdf94bdcb045762ee62b31c3",
            "247f8bc86e9e473f8dc465a8d4a73f73",
            "86ed49453f124b54ac4734ece4313c81",
            "6ac6e5db12e444649413f8c6a436b459",
            "00641e99263f49e7be07bfa3fde1e51b",
            "ac9746a24d8847ebb492091e11f9334b"
          ]
        },
        "outputId": "c1d82d71-09c2-4852-e290-0e3574e834e8"
      },
      "source": [
        "print('Loading tokenizer...')\n",
        "if MODEL == \"distilbert-base-uncased\":\n",
        "\n",
        "  from transformers import DistilBertTokenizer\n",
        "  tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case = True)\n",
        "\n",
        "elif MODEL == \"bert-base-cased\":\n",
        "\n",
        "  from transformers import BertTokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case = False)\n",
        "\n",
        "elif MODEL == \"roberta-base\":\n",
        "\n",
        "  from transformers import RobertaTokenizer\n",
        "  tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "else:\n",
        "  raise ValueError('Unknown model specified. Check MODEL var.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d354d7097264df8a423cfac210ef680",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a18080db34a046f181b57b354f19708b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJUNvf_8qaqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "05cdf6fa-7887-4d19-c3d3-a9e04a911d50"
      },
      "source": [
        "random_sample = random.randint(0,train_df.shape[0])\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[random_sample])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[random_sample]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[random_sample])))\n",
        "\n",
        "#Print the associated label\n",
        "print(\"Label: \", labels[random_sample])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  the absurdity\n",
            "Tokenized:  ['the', 'Ġabsurdity']\n",
            "Token IDs:  [627, 40020]\n",
            "Label:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-whFHrRxqpm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d18a237c-0572-4148-dac2-bb37160dde62"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "if max_len <= 512:\n",
        "  print('Max sentence length: ', max_len) #max sentence len for BERT is 512\n",
        "else:\n",
        "  warnings.warn(\"WARNING: max_len exceeds max token length for BERT.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecRa9_OArWZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "1566ad5f-467c-4970-8d22-7cdad60dddb0"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    #`encode_plus` will:\n",
        "    #(1) Tokenize the sentence.\n",
        "    #(2) Prepend the `[CLS]` token to the start.\n",
        "    #(3) Append the `[SEP]` token to the end.\n",
        "    #(4) Map tokens to their IDs.\n",
        "    #(5) Pad or truncate the sentence to `max_length`\n",
        "    #(6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,                         #Sentence to encode.\n",
        "        add_special_tokens = True,    #Add '[CLS]' and '[SEP]'\n",
        "        max_length = max_len,         #Pad & truncate all sentences.\n",
        "        truncation = True,\n",
        "        pad_to_max_length = True,\n",
        "        return_attention_mask = True, # Construct attn. masks.\n",
        "        return_tensors = 'pt',        # Return pytorch tensors.\n",
        "    )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence as a list of IDs.\n",
        "print('Original: ', sentences[random_sample])\n",
        "print('Token IDs:', input_ids[random_sample])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  the absurdity\n",
            "Token IDs: tensor([    0,   627, 40020,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xER2TbP-rqGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "887925ad-780c-4a26-9509-797922dd89dd"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14,335 training samples\n",
            "1,593 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHVTSNSVtTsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = BATCH_SIZE # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = BATCH_SIZE # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSTj69zcASO_",
        "colab_type": "text"
      },
      "source": [
        "# Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWq_YCbLuEja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5c469c4b5e24b178555fcd2d71217d6",
            "9bd7366069d24a09a96616f175728332",
            "267069f4c28248ed9e6a0b96ef505540",
            "84a9fb93a46345078a0640dd825e313f",
            "bc4accf27dce478caf2ca15e70a8046e",
            "fcaa4dfcf2204243be5f4ee414b81df5",
            "47ec3ad78fd44d24901f4f037aa8ddc7",
            "d45bca6976964c139dc72e0d6dc28607",
            "419275a22e9b4d37bac7e5b8358324a6",
            "9a4113ccc4fc4c1f88a501c9cd0df52d",
            "7842520d26a247dc82288b4bdf324276",
            "0b4e2abbe9fc4f108410047f58ca4c7d",
            "1c27d2f116414c6b8a98fa407a5f61fb",
            "72647df2b8bc47ee9959041bfe2c5920",
            "eca8b32cf837469d846fad1eef60c129",
            "748d235ca9f643f890cc0f8e5f055e22"
          ]
        },
        "outputId": "aa2c297f-2d54-4db5-e0a0-4417c11dd961"
      },
      "source": [
        "if MODEL == \"distilbert-base-uncased\":\n",
        "\n",
        "  from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "  model = DistilBertForSequenceClassification.from_pretrained(\n",
        "      \"distilbert-base-uncased\",\n",
        "      num_labels = NUM_LABELS,\n",
        "      output_attentions = False,\n",
        "      output_hidden_states = False,\n",
        "  )\n",
        "elif MODEL == \"bert-base-cased\":\n",
        "\n",
        "  from transformers import BertForSequenceClassification\n",
        "\n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels = NUM_LABELS,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "  \n",
        "elif MODEL == \"roberta-base\":\n",
        "\n",
        "  from transformers import RobertaForSequenceClassification\n",
        "\n",
        "  model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "\n",
        "else:\n",
        "  raise ValueError('Unknown model specified. Check MODEL var.')\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c469c4b5e24b178555fcd2d71217d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419275a22e9b4d37bac7e5b8358324a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3w5c_jBuScV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = LEARNING_RATE,\n",
        "    eps = 1e-8 #small weight to add to avoid zero weights\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYKlhNh5AYnU",
        "colab_type": "text"
      },
      "source": [
        "# Training & validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h26i5Cgufhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "    num_training_steps = total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzFDyuQRuzXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ppnvpu_lLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_metrics(preds, labels):\n",
        "  \"\"\"\n",
        "  Calculates a variety of metrics during validation steps in training.\n",
        "\n",
        "  Args:\n",
        "    preds - an array of prediction scores, one for each class being assessed. Will be an array of shape (n_samples,1).\n",
        "    labels - an array of the true labels for a given set of validation samples. Should also be an array of shape (n_samples, n_classes). \n",
        "\n",
        "  Returns:\n",
        "    result - a dictionary of metrics and their values.\n",
        "  \"\"\"\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  precision, recall, f1_micro, support = precision_recall_fscore_support(\n",
        "      y_true = labels_flat, \n",
        "      y_pred = preds_flat, \n",
        "      zero_division = 0, \n",
        "      average = \"micro\"\n",
        "  ) #using average = micro is consistent with LR & other models & SemEval metrics\n",
        "\n",
        "  f1_macro = f1_score(y_true = labels_flat, y_pred = preds_flat, average = \"macro\", zero_division = 0)\n",
        "\n",
        "  # softmax_score = softmax(preds, axis = 1)\n",
        "  # auc_only_pos = roc_auc_score(\n",
        "  #     y_true = labels_flat, \n",
        "  #     y_score = softmax_score,\n",
        "  #     multi_class = \"ovr\"\n",
        "  # ) #using all scores across all classes\n",
        "\n",
        "  result = {\n",
        "      \"Precision\": precision,\n",
        "      \"Recall\": recall,\n",
        "      \"F1_micro\": f1_micro,\n",
        "      \"F1_macro\": f1_macro\n",
        "  }\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIeS_U-4u3_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hilCF5eIu6e8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "0c94f58b-e227-4f3c-a140-b3520c6ad7a6"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "val_predictions, val_true_labels = [], []\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, EPOCHS):\n",
        "    \n",
        "    ##############\n",
        "    ## TRAINING ##\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # are given and what flags are set. Here it returns the loss and the logits.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    ################    \n",
        "    ## VALIDATION ##\n",
        "\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    total_eval_precision = 0\n",
        "    total_eval_recall = 0\n",
        "    total_eval_f1_micro = 0\n",
        "    total_eval_f1_macro = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        val_predictions.append(logits)\n",
        "        val_true_labels.append(label_ids)\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Calculate other metrics and accumulate over all batches\n",
        "        these_val_metrics = val_metrics(logits, label_ids)\n",
        "        total_eval_precision += these_val_metrics[\"Precision\"]\n",
        "        total_eval_recall += these_val_metrics[\"Recall\"]\n",
        "        total_eval_f1_micro += these_val_metrics[\"F1_micro\"]\n",
        "        total_eval_f1_macro += these_val_metrics[\"F1_macro\"]        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Calculate other metrics\n",
        "    avg_eval_precision = total_eval_precision/len(validation_dataloader)\n",
        "    avg_eval_recall = total_eval_recall/len(validation_dataloader)\n",
        "    avg_eval_f1_micro = total_eval_f1_micro/len(validation_dataloader)\n",
        "    avg_eval_f1_macro = total_eval_f1_macro/len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Avg. Accur.': avg_val_accuracy,\n",
        "            'Avg. Precision': avg_eval_precision,\n",
        "            'Avg. Recall': avg_eval_recall,\n",
        "            'Avg. F1_micro': avg_eval_f1_micro,\n",
        "            'Avg. F1_macro': avg_eval_f1_macro,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7cb7cc16b705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# single value; the `.item()` function just returns the Python value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# from the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7BudLdoAgfk",
        "colab_type": "text"
      },
      "source": [
        "# Assess training & validation performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgujpcXqvEfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBRC-lEK6eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_stats.describe().loc[\"mean\",[\"Avg. Accur.\",\"Avg. Precision\", \"Avg. Recall\", \"Avg. F1_micro\", \"Avg. F1_macro\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn--55R72G6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "93cef7e4-ebb3-45c6-cb14-e64eb2ab6ced"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks(range(1,EPOCHS+1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx5b-1dU4NUh",
        "colab_type": "text"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqkz02TP4O1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output_dir = './selected_model/'\n",
        "\n",
        "# # Create output directory if needed\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# # model_to_save.config.id2label = {i: le.classes_[i] for i in range(len(le.classes_))}\n",
        "# # model_to_save.config.label2id = {le.classes_[i]:i for i in range(len(le.classes_))}\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "# tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMWvmFsKrug2",
        "colab_type": "text"
      },
      "source": [
        "# END"
      ]
    }
  ]
}