{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we'll create tab-separated files of our training and dev datasets as well as generate negative spans from the news articles. \n",
    "\n",
    "## In EDA.ipynb we noted the training data only contains instances of positive spans. However, the rest of the news articles can be treated as negative spans (i.e. segments without propaganda). Since we want to train our classifiers on both positive and negative samples we can assign the negative spans with a label of \"No_Propaganda\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#FF8800\">  Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/train-articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for root, dirs, files in os.walk(PATH, topdown = True):\n",
    "    filenames = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable = [\"ner\"]) # don't need NER, can disable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [] # create a single string for each doc & add to list\n",
    "text_num = [] # capture the number/order in which each doc was processed\n",
    "counter = 0\n",
    "for name in filenames:\n",
    "    text_num.append((counter,name))\n",
    "    counter += 1\n",
    "    with open(PATH+name) as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc, Token, Span\n",
    "Span.set_extension(\"TRAIN_LABEL\", default = \"No_Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_as_docs = [] # create list where elements are separate docs\n",
    "for doc in nlp.pipe(texts):\n",
    "    docs_as_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_name_df = pd.DataFrame(text_num, columns = [\"element_in_list\", \"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_name_df[\"filenumber\"] = file_num_name_df.apply(lambda x: int(re.findall(\"\\d+\", x[\"filename\"])[0]), axis = 1)\n",
    "file_num_name_df = file_num_name_df[[\"filenumber\",\"filename\",\"element_in_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS = \"/home/bryan/Documents/Code/si630/semeval/datasets/train-task2-TC.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spans_df = pd.read_csv(TRAIN_LABELS, sep = \"\\t\", header = None, names = [\"filenumber\",\"label\",\"span_start\",\"span_end\"])\n",
    "all_spans_df = all_spans_df.merge(file_num_name_df, on = \"filenumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6129, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_spans_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#8800ff\"> There are +6,100 positive labeled spans in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_spans_df.iterrows():\n",
    "    try:\n",
    "        row_temp = row[1]\n",
    "        docs_as_docs[row_temp[\"element_in_list\"]].char_span(row_temp[\"span_start\"], row_temp[\"span_end\"])._.TRAIN_LABEL = row_temp[\"label\"]\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_spans_list = [] # create a list of nested tuples\n",
    "errors = []\n",
    "CONTEXT_WINDOW = 75\n",
    "\n",
    "for entry in all_spans_df[\"element_in_list\"].unique(): # iterate through unique entries in element_in_list\n",
    "    sub_df = all_spans_df[all_spans_df[\"element_in_list\"] == entry] # this is subset of main df containing only entries for the current doc\n",
    "    these_intervals = [(x[1][\"span_start\"], x[1][\"span_end\"]) for x in sub_df.iterrows()] # get intervals\n",
    "    this_tree = IntervalTree.from_tuples(these_intervals) # initialize tree with intervals\n",
    "    \n",
    "    this_doc = docs_as_docs[entry]\n",
    "    START_POINT = CONTEXT_WINDOW # char position we can start from\n",
    "    END_POINT = len(this_doc)-(CONTEXT_WINDOW) # char position we can work up until\n",
    "    for token in range(START_POINT, END_POINT): # for the range of possible center positions of the CONTEXT_WINDOW\n",
    "        if this_tree.overlap(token, token+CONTEXT_WINDOW):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                docs_as_docs[entry].char_span(token, token+CONTEXT_WINDOW)._.TRAIN_LABEL = \"No_Propaganda\"\n",
    "                neg_spans_list.append((entry, (token,token+CONTEXT_WINDOW)))\n",
    "            except Exception as e:\n",
    "                errors.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = [(docs_as_docs[i[0]].char_span(i[1][0],i[1][1]).text,\"No_Propaganda\") for i in neg_spans_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_spans_df.iterrows():\n",
    "    try:\n",
    "        full_list.append((docs_as_docs[i[1][\"element_in_list\"]].char_span(i[1][\"span_start\"],i[1][\"span_end\"]).text, i[1][\"label\"]))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_records(full_list, columns = ['text','label'])\n",
    "train_df[\"label_binary\"] = train_df.apply(lambda x: \"No_Propaganda\" if x[\"label\"] == \"No_Propaganda\" else \"Propaganda\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>nations grapple with the outbreak of the bubon...</td>\n",
       "      <td>No_Propaganda</td>\n",
       "      <td>No_Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>Of course they did, and of course they still do</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>now, we have all heard of Jesus Campos.\\nHe’s ...</td>\n",
       "      <td>No_Propaganda</td>\n",
       "      <td>No_Propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            label  \\\n",
       "1167   nations grapple with the outbreak of the bubon...    No_Propaganda   \n",
       "13237    Of course they did, and of course they still do  Loaded_Language   \n",
       "882    now, we have all heard of Jesus Campos.\\nHe’s ...    No_Propaganda   \n",
       "\n",
       "        label_binary  \n",
       "1167   No_Propaganda  \n",
       "13237     Propaganda  \n",
       "882    No_Propaganda  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"rand_letter\"] = \"s\" # apparently this is needed/expected by BERT\n",
    "train_data = train_df[[\"label\",\"label_binary\",\"rand_letter\",\"text\"]]\n",
    "train_data.index = train_data.index.rename(\"id\")\n",
    "train_data = train_data.sample(frac = 1).reset_index(drop = True) #randomly sorts the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15928, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#8800ff\"> We now have +15,900 labeled spans in our training data. An increase of 160%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"datasets/train_data.tsv\", sep = \"\\t\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#FF8800\">  Generate dev data\n",
    "> ### This is essentially the same code as above. I'm not adhering to DRY standards because I only need to run this code twice for this project and, overall, this setup (datasets, labels, etc.) won't generalize well to other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/dev-articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for root, dirs, files in os.walk(PATH, topdown=True):\n",
    "    filenames = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [] #create a single string for each doc & add to list\n",
    "text_to_num = []\n",
    "counter = 0\n",
    "for name in filenames:\n",
    "    text_to_num.append((counter,name))\n",
    "    counter += 1\n",
    "    with open(PATH+name) as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc, Token, Span\n",
    "Span.set_extension(\"DEV_LABEL\", default = \"No_Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_as_docs = []\n",
    "for doc in nlp.pipe(texts):\n",
    "    docs_as_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_name_df = pd.DataFrame(text_to_num, columns = [\"element_in_list\", \"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_name_df[\"filenumber\"] = file_num_name_df.apply(lambda x: int(re.findall(\"\\d+\", x[\"filename\"])[0]), axis = 1)\n",
    "file_num_name_df = file_num_name_df[[\"filenumber\",\"filename\",\"element_in_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_LABELS = \"datasets/dev-task-TC.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spans_df = pd.read_csv(DEV_LABELS, sep = \"\\t\", header = None, names = [\"filenumber\",\"label\",\"span_start\",\"span_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spans_df = all_spans_df.merge(file_num_name_df, on = \"filenumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_spans_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#8800ff\"> There are +1,000 positive labeled spans in the dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_spans_df.iterrows():\n",
    "    try:\n",
    "        row_temp = row[1]\n",
    "        docs_as_docs[row_temp[\"element_in_list\"]].char_span(row_temp[\"span_start\"], row_temp[\"span_end\"])._.DEV_LABEL = row_temp[\"label\"]\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_spans_list = [] # create a list of nested tuples\n",
    "errors = []\n",
    "CONTEXT_WINDOW = 75\n",
    "\n",
    "for entry in all_spans_df[\"element_in_list\"].unique(): # iterate through unique entries in element_in_list\n",
    "    sub_df = all_spans_df[all_spans_df[\"element_in_list\"] == entry] # this is subset of main df containing only entries for the current doc\n",
    "    these_intervals = [(x[1][\"span_start\"], x[1][\"span_end\"]) for x in sub_df.iterrows()] # get intervals\n",
    "    this_tree = IntervalTree.from_tuples(these_intervals) # initialize tree with intervals\n",
    "    \n",
    "    this_doc = docs_as_docs[entry]\n",
    "    START_POINT = CONTEXT_WINDOW # char position we can start from\n",
    "    END_POINT = len(this_doc)-(CONTEXT_WINDOW) # char position we can work up until\n",
    "    for token in range(START_POINT, END_POINT): # for the range of possible center positions of the CONTEXT_WINDOW\n",
    "        if this_tree.overlap(token, token+CONTEXT_WINDOW):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                docs_as_docs[entry].char_span(token, token+CONTEXT_WINDOW)._.TRAIN_LABEL = \"No_Propaganda\"\n",
    "                neg_spans_list.append((entry, (token,token+CONTEXT_WINDOW)))\n",
    "            except Exception as e:\n",
    "                errors.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = [(docs_as_docs[i[0]].char_span(i[1][0],i[1][1]).text,\"No_Propaganda\") for i in neg_spans_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_spans_df.iterrows():\n",
    "    try:\n",
    "        full_list.append((docs_as_docs[i[1][\"element_in_list\"]].char_span(i[1][\"span_start\"],i[1][\"span_end\"]).text, i[1][\"label\"]))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.DataFrame.from_records(full_list, columns = ['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df[\"label_binary\"] = dev_df.apply(lambda x: \"No_Propaganda\" if x[\"label\"] == \"No_Propaganda\" else \"Propaganda\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>report explaining the prosecution or declinati...</td>\n",
       "      <td>No_Propaganda</td>\n",
       "      <td>No_Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Agency.\\nPaul told CNN’s “State of the Union” ...</td>\n",
       "      <td>No_Propaganda</td>\n",
       "      <td>No_Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>does all of this while he stands accused of ab...</td>\n",
       "      <td>No_Propaganda</td>\n",
       "      <td>No_Propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          label  \\\n",
       "1397  report explaining the prosecution or declinati...  No_Propaganda   \n",
       "172   Agency.\\nPaul told CNN’s “State of the Union” ...  No_Propaganda   \n",
       "1040  does all of this while he stands accused of ab...  No_Propaganda   \n",
       "\n",
       "       label_binary  \n",
       "1397  No_Propaganda  \n",
       "172   No_Propaganda  \n",
       "1040  No_Propaganda  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df[\"rand_letter\"] = \"s\"\n",
    "dev_data = dev_df[[\"label\",\"label_binary\",\"rand_letter\",\"text\"]]\n",
    "dev_data.index = dev_data.index.rename(\"id\")\n",
    "dev_data = dev_data.sample(frac = 1).reset_index(drop = True) # randomly sorts the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2850, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#8800ff\"> We now have +2,800 labeled spans in our dev data. An increase of 168%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.to_csv(\"datasets/dev_data.tsv\", sep = \"\\t\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#FF8800\"> END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
